{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM :\n",
    "     \n",
    "    # Function here computes the winning vector\n",
    "    # by Euclidean distance\n",
    "    def winner( self, weights, sample ) :\n",
    "         \n",
    "        D0 = 0      \n",
    "        D1 = 0\n",
    "        D2 = 0\n",
    "        D3 = 0\n",
    "        D4 = 0\n",
    "        D5 = 0\n",
    "         \n",
    "        for i  in range( len( sample ) ) :\n",
    "            \n",
    "            try:\n",
    "                if(len(sample[i])>1):\n",
    "                    sample[i] = sample[i][0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            D0 = D0 + math.pow( ( sample[i] - weights[0][i] ), 2 )\n",
    "            D1 = D1 + math.pow( ( sample[i] - weights[1][i] ), 2 )\n",
    "            D2 = D2 + math.pow( ( sample[i] - weights[2][i] ), 2 )\n",
    "            D3 = D3 + math.pow( ( sample[i] - weights[3][i] ), 2 )\n",
    "            D4 = D4 + math.pow( ( sample[i] - weights[4][i] ), 2 )\n",
    "            D5 = D5 + math.pow( ( sample[i] - weights[5][i] ), 2 )\n",
    "             \n",
    "            #if D0 > D1 :\n",
    "                #return 0\n",
    "            #else :\n",
    "                #return 1\n",
    "            print('Distances: {}'.format(np.array([D0,D1,D2,D3,D4,D5])))\n",
    "            return np.argmax(np.array([D0,D1,D2,D3,D4,D5]))\n",
    "     \n",
    "    # Function here updates the winning vector\n",
    "    def update( self, weights, sample, J, alpha ) :\n",
    "        \n",
    "        for i in range( len ( weights[0] ) ) :\n",
    "            weights[J][i] = weights[J][i] + alpha * ( sample[i] - weights[J][i] )\n",
    " \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "Train = [\n",
    "     [1,1,1,1,1,1,1,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,1,1,1,1,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,1,1,1,1,1,1],\n",
    "     [1,1,1,1,1,1,1,  0,1,0,0,0,0,0,  0,1,0,0,0,0,0,  0,1,0,1,0,0,0,  0,1,1,1,0,0,0,  0,1,0,1,0,0,0,  0,1,0,0,0,0,0,  0,1,0,0,0,0,0,  1,1,1,1,1,1,1],\n",
    "     [0,0,0,1,0,0,0,  0,0,0,1,0,0,0,  0,0,0,1,0,0,0,  0,0,1,0,1,0,0,  0,0,1,0,1,0,0,  0,1,1,1,1,1,0,  0,1,0,0,0,1,0,  0,1,0,0,0,1,0,  1,1,1,0,1,1,1],\n",
    "     [0,0,0,1,0,0,0,  0,0,0,1,0,0,0,  0,0,1,0,1,0,0,  0,0,1,0,1,0,0,  0,1,0,0,0,1,0,  0,1,1,1,1,1,0,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1],\n",
    "     [1,1,1,1,1,1,1,  0,1,0,0,0,0,0,  0,1,0,0,0,0,0,  0,1,0,0,1,0,0,  0,1,1,1,1,0,0,  0,1,0,0,1,0,0,  0,1,0,0,0,0,0,  0,1,0,0,0,0,0,  1,1,1,1,1,1,1],\n",
    "     [0,0,0,1,0,0,0,  0,0,0,1,0,0,0,  0,0,0,1,0,0,0,  0,0,1,0,1,0,0,  0,0,1,0,1,0,0,  0,1,0,0,0,1,0,  0,1,1,1,1,1,0,  0,1,0,0,0,1,0,  0,1,0,0,0,1,0],\n",
    "     [1,0,0,0,0,1,0,  1,0,0,0,1,0,0,  1,0,0,1,0,0,0,  1,0,1,0,0,0,0,  1,1,0,0,0,0,0,  1,0,1,0,0,0,0,  1,0,0,1,0,0,0,  1,0,0,0,1,0,0,  1,0,0,0,0,1,0],\n",
    "     [1,1,1,1,1,1,0,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,1,1,1,1,0,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  1,1,1,1,1,1,0],\n",
    "     [0,0,1,1,1,1,1,  0,1,0,0,0,0,1,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  0,1,0,0,0,0,1,  0,0,1,1,1,1,1],\n",
    "     [1,1,1,1,1,1,0,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,1,1,1,1,1,0,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,1,1,1,1,1,0],\n",
    "     [0,0,1,1,1,0,0,  0,1,0,0,0,1,0,  1,0,0,0,0,0,1,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,1,  0,1,0,0,0,1,0,  0,0,1,1,1,0,0],\n",
    "     [0,0,0,1,1,1,1,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,1,0,0,0,1,0,  0,1,0,0,0,1,0,  0,0,1,1,1,0,0],\n",
    "     [0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,1,0,0,0,1,0,  0,1,0,0,0,1,0,  0,0,1,1,1,0,0],\n",
    "     [0,0,1,1,1,0,1,  0,1,0,0,0,1,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,0,  1,0,0,0,0,0,1,  0,1,0,0,0,1,0,  0,0,1,1,1,0,0],\n",
    "     [0,0,0,0,1,1,1,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,0,0,0,0,1,0,  0,1,0,0,0,1,0,  0,0,1,1,1,0,0],\n",
    "     [1,1,1,1,1,1,0,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,1,1,1,1,0,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  1,1,1,1,1,1,0],\n",
    "     [1,1,1,0,0,1,1,  0,1,0,0,1,0,0,  0,1,0,1,0,0,0,  0,1,1,0,0,0,0,  0,1,1,0,0,0,0,  0,1,0,1,0,0,0,  0,1,0,0,1,0,0,  0,1,0,0,0,1,0,  1,1,1,0,0,1,1],\n",
    "     [1,1,1,0,0,1,1,  0,1,0,0,0,1,0,  0,1,0,0,1,0,0,  0,1,0,1,0,0,0,  0,1,1,0,0,0,0,  0,1,0,1,0,0,0,  0,1,0,0,1,0,0,  0,1,0,0,0,1,0,  1,1,1,0,0,1,1]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "Test1 = [1,1,1,1,1,0,0,  1,0,0,0,0,1,0,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,0,1,  1,0,0,0,0,1,0,  1,1,1,1,1,0,0]\n",
    "Test2 = [1,1,1,1,1,0,0,  0,1,0,0,0,1,0,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,0,1,  0,1,0,0,0,1,0,  1,1,1,1,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data size (m,n)\n",
    "m = 18 # number of training examples \n",
    "n = 63 # number of features 9 * 7 \n",
    "c = 6 # number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "weights = np.random.rand(n,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [0.44444461 0.44444486 0.11129654 0.44444477 0.1112725  0.11122868]\n",
      "Winner cluster for sample 18 is : 1\n",
      "\n",
      "Distances: [0.44444461 0.11111121 0.11129654 0.44444477 0.1112725  0.11122868]\n",
      "Winner cluster for sample 18 is : 3\n",
      "\n",
      "Distances: [0.11111103 0.44444424 0.44407382 0.44444428 0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 3\n",
      "\n",
      "Distances: [0.11111103 0.44444424 0.44407382 0.11111107 0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 1\n",
      "\n",
      "Distances: [0.44444461 0.44444455 0.11129654 0.44444453 0.1112725  0.11122868]\n",
      "Winner cluster for sample 18 is : 0\n",
      "\n",
      "Distances: [0.44444436 0.11111106 0.44407382 0.11111107 0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 0\n",
      "\n",
      "Distances: [0.44444449 0.44444455 0.11129654 0.44444453 0.1112725  0.11122868]\n",
      "Winner cluster for sample 18 is : 1\n",
      "\n",
      "Distances: [0.44444449 0.11111114 0.11129654 0.44444453 0.1112725  0.11122868]\n",
      "Winner cluster for sample 18 is : 3\n",
      "\n",
      "Distances: [0.11111109 0.44444439 0.44407382 0.4444444  0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 3\n",
      "\n",
      "Distances: [0.44444449 0.11111114 0.11129654 0.44444446 0.1112725  0.11122868]\n",
      "Winner cluster for sample 18 is : 0\n",
      "\n",
      "Distances: [0.44444442 0.44444439 0.44407382 0.1111111  0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 0\n",
      "\n",
      "Distances: [0.11111111 0.44444439 0.44407382 0.1111111  0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 1\n",
      "\n",
      "Distances: [0.11111111 0.1111111  0.44407382 0.1111111  0.44412185 0.4442094 ]\n",
      "Winner cluster for sample 18 is : 5\n",
      "\n",
      "Distances: [0.11111111 0.1111111  0.44407382 0.1111111  0.44412185 0.11105235]\n",
      "Winner cluster for sample 18 is : 4\n",
      "\n",
      "Distances: [0.11111111 0.1111111  0.44407382 0.1111111  0.11103046 0.11105235]\n",
      "Winner cluster for sample 18 is : 2\n",
      "\n",
      "Distances: [0.44444446 0.44444447 0.44462981 0.44444446 0.44460578 0.44456199]\n",
      "Winner cluster for sample 18 is : 2\n",
      "\n",
      "Distances: [0.44444446 0.44444447 0.11115745 0.44444446 0.44460578 0.44456199]\n",
      "Winner cluster for sample 18 is : 4\n",
      "\n",
      "Distances: [0.44444446 0.44444447 0.11115745 0.44444446 0.11115145 0.44456199]\n",
      "Winner cluster for sample 18 is : 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "ob = SOM()\n",
    "\n",
    "epochs = 1\n",
    "alpha = 0.5\n",
    "\n",
    "for i in range( epochs ) :\n",
    "    for j in range( m ) :\n",
    "             \n",
    "        # training sample\n",
    "        sample = Train[j]\n",
    "             \n",
    "        # Compute winner vector\n",
    "        J = ob.winner( weights, sample )\n",
    "        print('Winner cluster for sample {0} is : {1}\\n'.format(m,J))\n",
    "         \n",
    "        # Update winning vector\n",
    "        weights = ob.update( weights, sample, J, alpha )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [0.44444446 0.44444447 0.11115745 0.44444446 0.11115145 0.1111405 ]\n",
      "Test1 Sample s belongs to Cluster :  1 \n",
      "\n",
      "\n",
      "Distances: [0.44444446 0.44444447 0.11115745 0.44444446 0.11115145 0.1111405 ]\n",
      "Test2 Sample s belongs to Cluster :  1\n",
      "\n",
      "\n",
      "Trained weights transposed for better display :\n",
      "\n",
      " [[0.333 0.333 0.667 0.333 0.667 0.667 0.568 0.877 0.687 0.101 0.53  0.028\n",
      "  0.367 0.761 0.689 0.073 0.594 0.428 0.827 0.409 0.571 0.403 0.497 0.039\n",
      "  0.776 0.875 0.453 0.457 0.77  0.412 0.13  0.128 0.247 0.492 0.014 0.491\n",
      "  0.99  0.923 0.528 0.979 0.409 0.313 0.076 0.032 0.237 0.362 0.71  0.98\n",
      "  0.953 0.826 0.829 0.518 0.174 0.824 0.577 0.306 0.107 0.596 0.408 0.534\n",
      "  0.659 0.631 0.104]\n",
      " [0.333 0.067 0.667 0.333 0.667 0.667 0.666 0.888 0.42  0.551 0.179 0.832\n",
      "  0.151 0.009 0.104 0.415 0.853 0.825 0.478 0.911 0.696 0.111 0.073 0.792\n",
      "  0.073 0.604 0.974 0.845 0.744 0.418 0.659 0.201 0.114 0.88  0.073 0.323\n",
      "  0.387 0.102 0.9   0.651 0.037 0.141 0.87  0.524 0.818 1.    0.349 0.436\n",
      "  0.898 0.42  0.55  0.778 0.454 0.28  0.33  0.648 0.535 0.069 0.296 0.44\n",
      "  0.893 0.205 0.097]\n",
      " [0.867 0.067 0.667 0.867 1.    0.667 0.409 0.597 0.937 0.812 0.232 0.283\n",
      "  0.487 0.45  0.525 0.726 0.7   0.982 0.467 0.583 0.917 0.253 0.199 0.48\n",
      "  0.212 0.571 0.953 0.309 0.227 0.025 0.047 0.342 0.798 0.768 0.57  0.963\n",
      "  0.519 0.712 0.007 0.562 0.736 0.708 0.947 0.667 0.201 0.591 0.302 0.702\n",
      "  0.203 0.569 0.836 0.778 0.424 0.527 0.461 0.895 0.866 0.008 0.386 0.254\n",
      "  0.111 0.042 0.992]\n",
      " [1.    0.733 0.667 1.    0.333 0.    0.538 0.441 0.542 0.553 0.386 0.14\n",
      "  0.668 0.41  0.859 0.06  0.94  0.764 0.839 0.759 0.932 0.853 0.477 0.969\n",
      "  0.589 0.416 0.732 0.482 0.192 0.252 0.937 0.592 0.195 0.89  0.746 0.646\n",
      "  0.586 0.929 0.999 0.989 0.795 0.223 0.153 0.052 0.088 0.998 0.422 0.538\n",
      "  0.34  0.905 0.695 0.618 0.091 0.232 0.876 0.021 0.004 0.962 0.91  0.34\n",
      "  0.73  0.816 0.447]\n",
      " [0.867 0.6   1.    0.867 0.333 0.    0.956 0.164 0.785 0.087 0.652 0.864\n",
      "  0.131 0.854 0.358 0.85  0.677 0.746 0.581 0.811 0.509 0.766 0.133 0.371\n",
      "  0.965 0.886 0.676 0.353 0.492 0.24  0.437 0.884 0.843 0.005 0.97  0.627\n",
      "  0.803 0.241 0.306 0.776 0.065 0.115 0.294 0.353 0.301 0.745 0.729 0.923\n",
      "  0.908 0.184 0.232 0.748 0.604 0.632 0.33  0.174 0.984 0.254 0.192 0.38\n",
      "  0.395 0.723 0.214]\n",
      " [0.333 0.867 1.    0.867 0.667 1.    0.688 0.121 0.161 0.719 0.94  0.306\n",
      "  0.846 0.338 0.855 0.48  0.9   0.495 0.076 0.207 0.034 0.077 0.081 0.182\n",
      "  0.506 0.303 0.182 0.029 0.469 0.191 0.952 0.962 0.056 0.202 0.42  0.737\n",
      "  0.595 0.663 0.079 0.192 0.302 0.496 0.619 0.342 0.101 0.571 0.753 0.205\n",
      "  0.909 0.68  0.665 0.643 0.85  0.697 0.783 0.955 0.895 0.215 0.743 0.295\n",
      "  0.449 0.857 0.904]]\n"
     ]
    }
   ],
   "source": [
    "# test and results\n",
    "J = ob.winner(weights, Test1)\n",
    "print( \"Test1 Sample s belongs to Cluster : \", J , \"\\n\\n\" )\n",
    "\n",
    "\n",
    "J = ob.winner(weights, Test2)\n",
    "print( \"Test2 Sample s belongs to Cluster : \", J )\n",
    "\n",
    "print( \"\\n\\nTrained weights transposed for better display :\\n\\n\", weights.T.round(3) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
