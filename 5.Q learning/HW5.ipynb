{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd4GU-Pf4vd9"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b8Ie-mkhiGjT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from gym import Env\n",
    "import datetime\n",
    "\n",
    "class FrozenLake(Env):\n",
    "    def __init__(self,studentNum:int=256, nonStationary = False):\n",
    "        self.studentNum = studentNum\n",
    "        self.nonStationary = nonStationary\n",
    "        \n",
    "        np.random.seed(self.studentNum)\n",
    "        self.beginMap = make_map(self.studentNum) #*2\n",
    "        self.beginMap[self.beginMap>1] = 1\n",
    "        self.endMap = make_map(self.studentNum + 100)\n",
    "        \n",
    "        self.changeDir = self.endMap - self.beginMap\n",
    "        self.changeDir *= 1/11000\n",
    "\n",
    "        self.fixedMap = self.beginMap\n",
    "\n",
    "        np.random.seed(datetime.datetime.now().microsecond)\n",
    "        \n",
    "        self.map = copy.deepcopy(self.fixedMap)\n",
    "        self.time = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.NSreset()\n",
    "        if not self.nonStationary:\n",
    "            self.map = copy.deepcopy(self.fixedMap)\n",
    "            self.time = 0\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    def NSreset(self):\n",
    "        self.time += 1\n",
    "        self.map += self.changeDir\n",
    "\n",
    "        self.map[self.map>0.95]=0.95\n",
    "        self.map[self.map<0.0]=0.0\n",
    "\n",
    "        self.state = (0,0)\n",
    "        self.done = False\n",
    "        return self.state\n",
    "    \n",
    "    def states_transitions(self, state, action):\n",
    "        x = state[0]\n",
    "        y = state[1]\n",
    "        states = np.array([[x,y-1], [x,y+1], [x-1 ,y], [x+1,y] ])\n",
    "\n",
    "\n",
    "        if action == UP:\n",
    "            selected = states[2]\n",
    "        if action == DOWN:\n",
    "            selected = states[3]\n",
    "        if action == RIGHT:\n",
    "            selected = states[1]\n",
    "        if action == LEFT:\n",
    "            selected = states[0]\n",
    "\n",
    "        zero = np.zeros((4,2)).astype(int)\n",
    "        three = (3 * np.ones((4,2))).astype(int)\n",
    "        output = np.maximum(np.minimum(states, three),zero)\n",
    "        output, indices = np.unique(output, axis = 0, return_counts= True)\n",
    "\n",
    "        \n",
    "        selected = np.maximum(np.minimum(selected, three[0]), zero[0])\n",
    "        probs = indices * 0.025\n",
    "        probs[np.argmax(np.sum(selected == output, axis = 1))] += 0.9\n",
    "\n",
    "        return list(zip(output[:,0],output[:,1])), probs\n",
    "    \n",
    "    def possible_consequences(self,action:int,state_now=None):\n",
    "\n",
    "        if state_now==None:\n",
    "            state_now = self.state\n",
    "\n",
    "        state = [state_now[0],state_now[1]]\n",
    "        states, probs = self.states_transitions(state, action)\n",
    "        aa = np.array(states) \n",
    "        fail_probs = self.map[(aa[:,0]),(aa[:,1])]\n",
    "        dones = np.sum(aa == 3, axis = 1) == 2\n",
    "        return states, probs, fail_probs,dones\n",
    "    \n",
    "    def step(self, a:int):\n",
    "        if not (a in range(4)):\n",
    "            raise Exception(\"{} action is not available!!!\".format(a))\n",
    "        \n",
    "        states, probs, fail_probs,dones = self.possible_consequences(a)\n",
    "        \n",
    "        next_idx = np.random.choice(np.arange(len(states)), p = probs)\n",
    "        next_state = states[next_idx]\n",
    "        self.state = tuple(next_state)\n",
    "        \n",
    "        self.done = dones[next_idx]\n",
    "\n",
    "        r = -1\n",
    "\n",
    "        if self.done:\n",
    "            r += 60\n",
    "        elif np.random.rand()< fail_probs[next_idx]:\n",
    "            r -= 15\n",
    "            self.done = True\n",
    "\n",
    "        return (self.state, r, self.done, {})\n",
    "\n",
    "    def render(self,state=None):\n",
    "        if state == None:\n",
    "            state = self.state\n",
    "\n",
    "        out = \"\"\n",
    "        for i in range(4):\n",
    "            out += \"\\n------------------------------\\n| \"\n",
    "            for j in range(4):\n",
    "                if (i,j) == state:\n",
    "                    out += \"\\033[44m{:.3f}\\033[0m | \".format(self.map[i,j])\n",
    "                else :\n",
    "                    out += \"{:.3f} | \".format(self.map[i,j])\n",
    "\n",
    "        out += \"\\n------------------------------\"\n",
    "        print(out)\n",
    "\n",
    "    def environment_states(self):\n",
    "        env_states = []\n",
    "        for state_index in range(16):\n",
    "            s0 = state_index % 4\n",
    "            s1 = state_index//4\n",
    "            env_states.append((s0,s1))\n",
    "        return env_states\n",
    "\n",
    "        \n",
    "def set_max_min(var,maximum,minimum):\n",
    "    return min(max(var,minimum),maximum)\n",
    "\n",
    "def make_map(studentNum):\n",
    "    np.random.seed(studentNum)  \n",
    "    move = np.zeros(6)\n",
    "    idx = np.random.choice(range(6),size=3,replace=False)\n",
    "    move[idx] = 1\n",
    "\n",
    "    point = [0,0]\n",
    "    lowprobs = [tuple(point)]\n",
    "\n",
    "    for m in move:\n",
    "        if m:\n",
    "            point[0] += 1\n",
    "        else:\n",
    "            point[1] += 1\n",
    "        lowprobs.append(tuple(point))\n",
    "    \n",
    "    map = np.random.rand(4,4)\n",
    "    idx = np.array(lowprobs)\n",
    "\n",
    "    map[idx[:,0],idx[:,1]] = 0.001 \n",
    "    map[0,0] = 0.0\n",
    "    map[3,3] = 0.0 \n",
    "\n",
    "    return map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIrM2PNQ4l5G"
   },
   "source": [
    "## Your Student ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JvWeNrBx4or9"
   },
   "outputs": [],
   "source": [
    "STUDENT_NUM = 400722138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba-NtxEn5LJ0"
   },
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "54H4VswF5Kot"
   },
   "outputs": [],
   "source": [
    "#%% allowed actions\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "ACTIONS = [LEFT,DOWN,RIGHT,UP]\n",
    "\n",
    "#%% hyperparameters\n",
    "EPISODES = 10000\n",
    "EPSILON = 0.1\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdub8jub5bM9"
   },
   "source": [
    "## Map of environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ME5gllo7g0p7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with fail probabilities :\n",
      "\n",
      "------------------------------\n",
      "| \u001b[44m0.000\u001b[0m | 0.001 | 0.001 | 0.082 | \n",
      "------------------------------\n",
      "| 0.526 | 0.493 | 0.001 | 0.217 | \n",
      "------------------------------\n",
      "| 0.579 | 0.570 | 0.001 | 0.001 | \n",
      "------------------------------\n",
      "| 0.344 | 0.356 | 0.249 | 0.000 | \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "environment = FrozenLake(studentNum=STUDENT_NUM)\n",
    "\n",
    "print(\"Environment with fail probabilities :\")\n",
    "environment.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z-KEpaeOcAh"
   },
   "source": [
    "## <h2><font color=indigo> Agent Implementation\n",
    "Implement your q-learning (off-policy TD) agent here. You need to utilize the step function provided in the Environment class to interact with frozen lake environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "9P-5IZqIeco8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "class Q_Learning:\n",
    "    def __init__(self, id, environment, discount , learning_rate = 0.1 , epsilon = 0.1 ,episodes=10000):\n",
    "\n",
    "        self.environment = environment\n",
    "        self.discount = discount\n",
    "        self.episodes = episodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.environment = environment\n",
    "        self.epsilon = epsilon\n",
    "        self.n_actions = 4\n",
    "\n",
    "\n",
    "    ######## Your Code Here ########\n",
    "    def learn(self):\n",
    "        G = []\n",
    "        for episode in range(self.episodes):\n",
    "            s = self.environment.reset()\n",
    "            G_episode=0\n",
    "            done=False\n",
    "            episode_length=0\n",
    "            \n",
    "            while episode_length <=100:##  episode must be finished in 100 steps\n",
    "                if random.random() < self.epsilon:## choose action epslone greedy\n",
    "                    a = random.randrange(0,4)## pick a random action\n",
    "                else:\n",
    "                    a = np.argmax(self.environment.map[s[0],:])##choose an action\n",
    "                    \n",
    "                s_next,r,done,_=self.environment.step(a)\n",
    "                \n",
    "                ## update Q\n",
    "                self.environment.map[s,a]=self.environment.map[s,a]+self.learning_rate*( r + self.discount*np.max(self.environment.map[s_next,:])-self.environment.map[s,a])\n",
    "                \n",
    "                G_episode+=r\n",
    "                \n",
    "                s = s_next\n",
    "                \n",
    "                episode_length += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                if done == True:\n",
    "                    break\n",
    "            \n",
    "            G.append(G_episode)\n",
    "        \n",
    "        self.environment.render()\n",
    "        print(sum(G)/self.episodes) \n",
    "        plt.plot(np.cumsum(Q)/np.arange(1,self.episodes+1),'.')\n",
    "        return G, self.environment.map\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6J4uXQGuTgs"
   },
   "source": [
    "## <h2><font color=indigo> Q Values\n",
    "Return the Q values that your agent learns in here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "WYZfiWY6qMch"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "| 0.000 | -7.763 | 0.001 | -0.223 | \n",
      "------------------------------\n",
      "| 0.526 | \u001b[44m-7.517\u001b[0m | 0.001 | 0.217 | \n",
      "------------------------------\n",
      "| 0.579 | 0.570 | 0.001 | 0.001 | \n",
      "------------------------------\n",
      "| 0.344 | 0.356 | 0.249 | 0.000 | \n",
      "------------------------------\n",
      "-17.1543\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Q_Learning('Poorya Mohammadi', environment, 0.9 , learning_rate = 0.5 , epsilon = 0.1 ,episodes= 10000)\n",
    "Q , policy = agent.learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMojYRGVvAXk"
   },
   "source": [
    "## <h2><font color=darkcyan> Policy\n",
    "Return the optimal policy that your agent learns in here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "9EFY3T0r9OHW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -7.76300268e+00,  1.00000000e-03,\n",
       "        -2.22736851e-01],\n",
       "       [ 5.25549606e-01, -7.51676651e+00,  1.00000000e-03,\n",
       "         2.17184859e-01],\n",
       "       [ 5.78585102e-01,  5.69779445e-01,  1.00000000e-03,\n",
       "         1.00000000e-03],\n",
       "       [ 3.43598863e-01,  3.56233756e-01,  2.49387570e-01,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StudentName__HW5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
